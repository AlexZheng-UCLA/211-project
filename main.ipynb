{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BrotherMingGame</td>\n",
       "      <td>2023-12-19 06:58:00+00:00</td>\n",
       "      <td>Hasboro laying off 1100 employees right before...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Fiendlyg</td>\n",
       "      <td>2023-12-19 06:56:00+00:00</td>\n",
       "      <td>I follow back in 1 SECOND all below 83K \\r\\n(T...</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@NekoSurfAI</td>\n",
       "      <td>2023-12-19 06:53:00+00:00</td>\n",
       "      <td>Good morning Master. Come we have to wake up.....</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rowancheung</td>\n",
       "      <td>2023-12-19 06:51:00+00:00</td>\n",
       "      <td>A new DeepMind paper just revealed that LLMs s...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AssTransformers</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>Oh, that's Hasbro laying off 1100 employees an...</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@rowancheung</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>A new AI study found that automated bots can n...</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@rowancheung</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>Jailed opposition leader Imran Khan just used ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@_svs_</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>So many Gen AI startups hiring now. \\r\\n\\r\\nTh...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@rowancheung</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>OpenAI just published a new safety preparednes...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@rowancheung</td>\n",
       "      <td>2023-12-19 06:50:00+00:00</td>\n",
       "      <td>Huge developments in the world of AI today.\\r\\...</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                  timestamp  \\\n",
       "0  @BrotherMingGame  2023-12-19 06:58:00+00:00   \n",
       "1         @Fiendlyg  2023-12-19 06:56:00+00:00   \n",
       "2       @NekoSurfAI  2023-12-19 06:53:00+00:00   \n",
       "3      @rowancheung  2023-12-19 06:51:00+00:00   \n",
       "4  @AssTransformers  2023-12-19 06:50:00+00:00   \n",
       "5      @rowancheung  2023-12-19 06:50:00+00:00   \n",
       "6      @rowancheung  2023-12-19 06:50:00+00:00   \n",
       "7            @_svs_  2023-12-19 06:50:00+00:00   \n",
       "8      @rowancheung  2023-12-19 06:50:00+00:00   \n",
       "9      @rowancheung  2023-12-19 06:50:00+00:00   \n",
       "\n",
       "                                                text  likes  replies  \\\n",
       "0  Hasboro laying off 1100 employees right before...     40        3   \n",
       "1  I follow back in 1 SECOND all below 83K \\r\\n(T...     45       19   \n",
       "2  Good morning Master. Come we have to wake up.....     24        1   \n",
       "3  A new DeepMind paper just revealed that LLMs s...     17        1   \n",
       "4  Oh, that's Hasbro laying off 1100 employees an...     63        4   \n",
       "5  A new AI study found that automated bots can n...     19        2   \n",
       "6  Jailed opposition leader Imran Khan just used ...     39        1   \n",
       "7  So many Gen AI startups hiring now. \\r\\n\\r\\nTh...     28        4   \n",
       "8  OpenAI just published a new safety preparednes...     15        2   \n",
       "9  Huge developments in the world of AI today.\\r\\...     78        7   \n",
       "\n",
       "   retweets  quotes  \n",
       "0        13       0  \n",
       "1        20       0  \n",
       "2         4       0  \n",
       "3         1       0  \n",
       "4        11       0  \n",
       "5         3       2  \n",
       "6         8       5  \n",
       "7         1       1  \n",
       "8         3       0  \n",
       "9        18       1  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('X_Dec_2023.csv')\n",
    "\n",
    "selected_columns = ['username', 'timestamp', 'text', 'likes', 'replies', 'retweets', 'quotes']\n",
    "df = df[selected_columns]\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "# df = df.dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1932\n",
      "12367\n",
      "32.89126592875081\n",
      "205.26797507208633\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# add number of words in each tweet\n",
    "df['num_words'] = df['text'].apply(lambda x: len(x.split()))\n",
    "# add number of characters in each tweet\n",
    "df['num_chars'] = df['text'].apply(lambda x: len(x))\n",
    "\n",
    "# add length of each tweet\n",
    "print(df['num_words'].max())\n",
    "print(df['num_chars'].max())\n",
    "print(df['num_words'].mean())\n",
    "print(df['num_chars'].mean())\n",
    "df['length'] = np.minimum(df['num_words'] * 1.0 / 50, 10) + np.minimum(df['num_chars'] * 1.0 / 500, 10)\n",
    "df['length'] = np.maximum(df['length'], 1)\n",
    "\n",
    "# add number of sentences and new line in each tweet\n",
    "df['num_sentences'] = df['text'].apply(lambda x: len(re.split('\\n|\\.', x)))\n",
    "# add complexity of each tweet\n",
    "df['complexity'] = df['num_words'] / (df['num_sentences'] + 1)\n",
    "\n",
    "# group by username and calculate the time diff between each tweet\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['username', 'timestamp'])\n",
    "df['time_diff'] = df.groupby('username')['timestamp'].diff().fillna(pd.Timedelta(seconds=0))\n",
    "# transform time_diff to minutes\n",
    "df['time_diff'] = df['time_diff'].apply(lambda x: x.total_seconds() / 60)\n",
    "# only keep the users who have more than 3 tweet\n",
    "df = df.groupby('username').filter(lambda x: len(x) > 10)\n",
    "df = df.groupby('username').filter(lambda x:  100 < x['likes'].mean() < 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>quotes</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>complexity</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>next_length</th>\n",
       "      <th>next_complexity</th>\n",
       "      <th>next_tweet_time_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-19 05:41:00+00:00</td>\n",
       "      <td>Catwalk: A Unified Language Model Evaluation F...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1176</td>\n",
       "      <td>5.652</td>\n",
       "      <td>16</td>\n",
       "      <td>9.705882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.742</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-19 05:51:00+00:00</td>\n",
       "      <td>Cascade Speculative Drafting for Even Faster L...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1011</td>\n",
       "      <td>4.742</td>\n",
       "      <td>16</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.028</td>\n",
       "      <td>12.058824</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-19 14:56:00+00:00</td>\n",
       "      <td>An In-depth Look at Gemini's Language Abilitie...</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>205</td>\n",
       "      <td>1464</td>\n",
       "      <td>7.028</td>\n",
       "      <td>16</td>\n",
       "      <td>12.058824</td>\n",
       "      <td>545.0</td>\n",
       "      <td>8.584</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-20 02:25:00+00:00</td>\n",
       "      <td>A Challenger to GPT-4V? Early Explorations of ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>1822</td>\n",
       "      <td>8.584</td>\n",
       "      <td>18</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>689.0</td>\n",
       "      <td>6.858</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>1505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-20 19:30:00-08:00</td>\n",
       "      <td>PowerInfer: Fast Large Language Model Serving ...</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>1429</td>\n",
       "      <td>6.858</td>\n",
       "      <td>18</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>5.508</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-20 19:34:00-08:00</td>\n",
       "      <td>Mini-GPTs: Efficient Large Language Models thr...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>1204</td>\n",
       "      <td>5.508</td>\n",
       "      <td>14</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.084</td>\n",
       "      <td>17.866667</td>\n",
       "      <td>7142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 02:36:00+00:00</td>\n",
       "      <td>LLM4VG: Large Language Models Evaluation for V...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>1862</td>\n",
       "      <td>9.084</td>\n",
       "      <td>14</td>\n",
       "      <td>17.866667</td>\n",
       "      <td>7142.0</td>\n",
       "      <td>5.218</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 02:56:00+00:00</td>\n",
       "      <td>Exploiting Novel GPT-4 APIs\\r\\n\\r\\npaper page:...</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>1059</td>\n",
       "      <td>5.218</td>\n",
       "      <td>14</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.042</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 03:29:00+00:00</td>\n",
       "      <td>InternVL: Scaling up Vision Foundation Models ...</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>441</td>\n",
       "      <td>2.042</td>\n",
       "      <td>10</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.998</td>\n",
       "      <td>13.684211</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 04:52:00+00:00</td>\n",
       "      <td>Generative AI Beyond LLMs: System Implications...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>1899</td>\n",
       "      <td>8.998</td>\n",
       "      <td>18</td>\n",
       "      <td>13.684211</td>\n",
       "      <td>83.0</td>\n",
       "      <td>9.900</td>\n",
       "      <td>13.714286</td>\n",
       "      <td>1341.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       username                  timestamp  \\\n",
       "91    @_akhaliq  2023-12-19 05:41:00+00:00   \n",
       "28    @_akhaliq  2023-12-19 05:51:00+00:00   \n",
       "604   @_akhaliq  2023-12-19 14:56:00+00:00   \n",
       "545   @_akhaliq  2023-12-20 02:25:00+00:00   \n",
       "1972  @_akhaliq  2023-12-20 19:30:00-08:00   \n",
       "1783  @_akhaliq  2023-12-20 19:34:00-08:00   \n",
       "3228  @_akhaliq  2023-12-26 02:36:00+00:00   \n",
       "3239  @_akhaliq  2023-12-26 02:56:00+00:00   \n",
       "3227  @_akhaliq  2023-12-26 03:29:00+00:00   \n",
       "3154  @_akhaliq  2023-12-26 04:52:00+00:00   \n",
       "\n",
       "                                                   text  likes  replies  \\\n",
       "91    Catwalk: A Unified Language Model Evaluation F...     16        0   \n",
       "28    Cascade Speculative Drafting for Even Faster L...     40        0   \n",
       "604   An In-depth Look at Gemini's Language Abilitie...     57        3   \n",
       "545   A Challenger to GPT-4V? Early Explorations of ...     20        0   \n",
       "1972  PowerInfer: Fast Large Language Model Serving ...    169        5   \n",
       "1783  Mini-GPTs: Efficient Large Language Models thr...    150        0   \n",
       "3228  LLM4VG: Large Language Models Evaluation for V...     59        0   \n",
       "3239  Exploiting Novel GPT-4 APIs\\r\\n\\r\\npaper page:...    127        4   \n",
       "3227  InternVL: Scaling up Vision Foundation Models ...     82        1   \n",
       "3154  Generative AI Beyond LLMs: System Implications...     63        0   \n",
       "\n",
       "      retweets  quotes  num_words  num_chars  length  num_sentences  \\\n",
       "91           4       1        165       1176   5.652             16   \n",
       "28           5       0        136       1011   4.742             16   \n",
       "604          9       3        205       1464   7.028             16   \n",
       "545          5       1        247       1822   8.584             18   \n",
       "1972        28       7        200       1429   6.858             18   \n",
       "1783        42       5        155       1204   5.508             14   \n",
       "3228        16       0        268       1862   9.084             14   \n",
       "3239        20       5        155       1059   5.218             14   \n",
       "3227        11       1         58        441   2.042             10   \n",
       "3154        19       0        260       1899   8.998             18   \n",
       "\n",
       "      complexity  time_diff  next_length  next_complexity  next_tweet_time_gap  \n",
       "91      9.705882        0.0        4.742         8.000000                 10.0  \n",
       "28      8.000000       10.0        7.028        12.058824                545.0  \n",
       "604    12.058824      545.0        8.584        13.000000                689.0  \n",
       "545    13.000000      689.0        6.858        10.526316               1505.0  \n",
       "1972   10.526316     1505.0        5.508        10.333333                  4.0  \n",
       "1783   10.333333        4.0        9.084        17.866667               7142.0  \n",
       "3228   17.866667     7142.0        5.218        10.333333                 20.0  \n",
       "3239   10.333333       20.0        2.042         5.272727                 33.0  \n",
       "3227    5.272727       33.0        8.998        13.684211                 83.0  \n",
       "3154   13.684211       83.0        9.900        13.714286               1341.0  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['next_length'] = df.groupby('username')['length'].shift(-1)\n",
    "df['next_complexity'] = df.groupby('username')['complexity'].shift(-1)\n",
    "df['next_tweet_time_gap'] = df.groupby('username')['time_diff'].shift(-1)\n",
    "df = df.dropna(subset=['next_length', 'next_complexity'])\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 8.21\n",
      "R²: 0.38\n",
      "Coefficients: [-0.03551273 -0.4268764   0.21733195  0.1929561 ]\n",
      "Intercept: 4.559222828033974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Independent variables\n",
    "X = df[['likes', 'replies', 'retweets', 'quotes']]\n",
    "\n",
    "# Dependent variable, assuming you start with predicting 'next_length'\n",
    "y1 = df['next_length']\n",
    "y2 = df['next_complexity']\n",
    "y3 = df['next_tweet_time_gap']\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R²: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Log Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.47\n",
      "R²: 0.40\n",
      "Coefficients: [-0.33999488  0.01649804  0.0568638  -0.01823643]\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(0, np.finfo(float).eps)\n",
    "df['log_likes'] = np.log(df['likes'])\n",
    "df['log_replies'] = np.log(df['replies'])\n",
    "df['log_quotes'] = np.log(df['quotes'])\n",
    "df['log_retweets'] = np.log(df['retweets'])\n",
    "df['log_next_length'] = np.log(df['next_length'])\n",
    "df['log_next_complexity'] = np.log(df['next_complexity'])\n",
    "df['log_next_tweet_time_gap'] = np.log(df['next_tweet_time_gap'])\n",
    "\n",
    "X_log = df[['log_likes', 'log_replies', 'log_retweets', 'log_quotes']]\n",
    "\n",
    "# Dependent variable for the example\n",
    "y1_log = df['log_next_length']\n",
    "y2_log = df['log_next_complexity']\n",
    "y3_log = df['log_next_tweet_time_gap']\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log, y1_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model_log = LinearRegression()\n",
    "model_log.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log = model_log.predict(X_test_log)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_log, y_pred_log))\n",
    "print('R²: %.2f' % r2_score(y_test_log, y_pred_log))\n",
    "print('Coefficients:', model_log.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sort_values(by=['username', 'timestamp'])\n",
    "k = 3\n",
    "\n",
    "# Create lagged features for the past three tweets\n",
    "for lag in range(1, k):  # 1, 2\n",
    "    df[f'likes_lag_{lag}'] = df.groupby('username')['likes'].shift(lag)\n",
    "    df[f'replies_lag_{lag}'] = df.groupby('username')['replies'].shift(lag)\n",
    "    df[f'retweets_lag_{lag}'] = df.groupby('username')['retweets'].shift(lag)\n",
    "    df[f'quotes_lag_{lag}'] = df.groupby('username')['quotes'].shift(lag)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "feature_columns = ['likes', 'replies', 'retweets', 'quotes'] + \\\n",
    "                  [f'{metric}_lag_{lag}' for metric in ['likes', 'replies', 'retweets', 'quotes'] for lag in range(1, k)]\n",
    "\n",
    "X = df[feature_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 63.13\n",
      "R²: -5.89\n",
      "Coefficients: [ 0.00253965 -0.20041647  0.08347753  0.25164765  0.01964136 -0.02434141\n",
      "  1.32869883  0.31767713 -0.23437426  0.46436111  0.00534071  0.26578767]\n",
      "Intercept: -1.4294423825984737\n"
     ]
    }
   ],
   "source": [
    "y1 = df['next_length']\n",
    "y2 = df['next_complexity']\n",
    "y3 = df['next_tweet_time_gap']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R²: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Coefficients:', model.coef_) \n",
    "print('Intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Log Linear Regression with Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in range(1, k):  # 1, 2\n",
    "    df[f'log_likes_lag_{lag}'] = df.groupby('username')['log_likes'].shift(lag)\n",
    "    df[f'log_replies_lag_{lag}'] = df.groupby('username')['log_replies'].shift(lag)\n",
    "    df[f'log_retweets_lag_{lag}'] = df.groupby('username')['log_retweets'].shift(lag)\n",
    "    df[f'log_quotes_lag_{lag}'] = df.groupby('username')['log_quotes'].shift(lag)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "feature_columns = ['likes', 'replies', 'retweets', 'quotes'] + \\\n",
    "                  [f'{metric}_lag_{lag}' for metric in ['likes', 'replies', 'retweets', 'quotes'] for lag in range(1, k)]\n",
    "\n",
    "X = df[feature_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.22\n",
      "R²: -3.78\n",
      "Coefficients: [-0.00630158  0.19346499  0.0527344  -0.13083759  0.01454434  0.01513702\n",
      "  0.44895178  0.29500037 -0.04551227  0.02010813 -0.05279361 -0.25852628]\n",
      "Intercept: -1.612512747522549\n"
     ]
    }
   ],
   "source": [
    "y1_log = df['log_next_length']\n",
    "y2_log = df['log_next_complexity']\n",
    "y3_log = df['log_next_tweet_time_gap']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1_log, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R²: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Coefficients:', model.coef_) \n",
    "print('Intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>quotes</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>retweets_lag_2</th>\n",
       "      <th>quotes_lag_2</th>\n",
       "      <th>log_likes_lag_1</th>\n",
       "      <th>log_replies_lag_1</th>\n",
       "      <th>log_retweets_lag_1</th>\n",
       "      <th>log_quotes_lag_1</th>\n",
       "      <th>log_likes_lag_2</th>\n",
       "      <th>log_replies_lag_2</th>\n",
       "      <th>log_retweets_lag_2</th>\n",
       "      <th>log_quotes_lag_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-20 19:30:00-08:00</td>\n",
       "      <td>PowerInfer: Fast Large Language Model Serving ...</td>\n",
       "      <td>169</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>200</td>\n",
       "      <td>1429</td>\n",
       "      <td>6.858</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-20 19:34:00-08:00</td>\n",
       "      <td>Mini-GPTs: Efficient Large Language Models thr...</td>\n",
       "      <td>150</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>155</td>\n",
       "      <td>1204</td>\n",
       "      <td>5.508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 02:36:00+00:00</td>\n",
       "      <td>LLM4VG: Large Language Models Evaluation for V...</td>\n",
       "      <td>59</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>268</td>\n",
       "      <td>1862</td>\n",
       "      <td>9.084</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 02:56:00+00:00</td>\n",
       "      <td>Exploiting Novel GPT-4 APIs\\r\\n\\r\\npaper page:...</td>\n",
       "      <td>127</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>155</td>\n",
       "      <td>1059</td>\n",
       "      <td>5.218</td>\n",
       "      <td>...</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 03:29:00+00:00</td>\n",
       "      <td>InternVL: Scaling up Vision Foundation Models ...</td>\n",
       "      <td>82</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>58</td>\n",
       "      <td>441</td>\n",
       "      <td>2.042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 04:52:00+00:00</td>\n",
       "      <td>Generative AI Beyond LLMs: System Implications...</td>\n",
       "      <td>63</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>260</td>\n",
       "      <td>1899</td>\n",
       "      <td>8.998</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>@_akhaliq</td>\n",
       "      <td>2023-12-26 19:13:00-08:00</td>\n",
       "      <td>Gemini vs GPT-4V: A Preliminary Comparison and...</td>\n",
       "      <td>203</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>288</td>\n",
       "      <td>2070</td>\n",
       "      <td>9.900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>@futuristflower</td>\n",
       "      <td>2023-12-21 15:29:00+00:00</td>\n",
       "      <td>1) When I had closed beta access to DALL-E 2, ...</td>\n",
       "      <td>85</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>54</td>\n",
       "      <td>280</td>\n",
       "      <td>1.640</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>@futuristflower</td>\n",
       "      <td>2023-12-21 15:33:00+00:00</td>\n",
       "      <td>I mean even MJ V5 looks better in faces and ph...</td>\n",
       "      <td>91</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>50</td>\n",
       "      <td>280</td>\n",
       "      <td>1.560</td>\n",
       "      <td>...</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>@futuristflower</td>\n",
       "      <td>2023-12-23 01:52:00+00:00</td>\n",
       "      <td>GPT-4 when doing a web search is the closest w...</td>\n",
       "      <td>137</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>-36.043653</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                  timestamp  \\\n",
       "1972        @_akhaliq  2023-12-20 19:30:00-08:00   \n",
       "1783        @_akhaliq  2023-12-20 19:34:00-08:00   \n",
       "3228        @_akhaliq  2023-12-26 02:36:00+00:00   \n",
       "3239        @_akhaliq  2023-12-26 02:56:00+00:00   \n",
       "3227        @_akhaliq  2023-12-26 03:29:00+00:00   \n",
       "3154        @_akhaliq  2023-12-26 04:52:00+00:00   \n",
       "3708        @_akhaliq  2023-12-26 19:13:00-08:00   \n",
       "1895  @futuristflower  2023-12-21 15:29:00+00:00   \n",
       "1894  @futuristflower  2023-12-21 15:33:00+00:00   \n",
       "2685  @futuristflower  2023-12-23 01:52:00+00:00   \n",
       "\n",
       "                                                   text  likes       replies  \\\n",
       "1972  PowerInfer: Fast Large Language Model Serving ...    169  5.000000e+00   \n",
       "1783  Mini-GPTs: Efficient Large Language Models thr...    150  2.220446e-16   \n",
       "3228  LLM4VG: Large Language Models Evaluation for V...     59  2.220446e-16   \n",
       "3239  Exploiting Novel GPT-4 APIs\\r\\n\\r\\npaper page:...    127  4.000000e+00   \n",
       "3227  InternVL: Scaling up Vision Foundation Models ...     82  1.000000e+00   \n",
       "3154  Generative AI Beyond LLMs: System Implications...     63  2.220446e-16   \n",
       "3708  Gemini vs GPT-4V: A Preliminary Comparison and...    203  6.000000e+00   \n",
       "1895  1) When I had closed beta access to DALL-E 2, ...     85  2.220446e-16   \n",
       "1894  I mean even MJ V5 looks better in faces and ph...     91  2.220446e-16   \n",
       "2685  GPT-4 when doing a web search is the closest w...    137  2.220446e-16   \n",
       "\n",
       "      retweets        quotes  num_words  num_chars  length  ...  \\\n",
       "1972      28.0  7.000000e+00        200       1429   6.858  ...   \n",
       "1783      42.0  5.000000e+00        155       1204   5.508  ...   \n",
       "3228      16.0  2.220446e-16        268       1862   9.084  ...   \n",
       "3239      20.0  5.000000e+00        155       1059   5.218  ...   \n",
       "3227      11.0  1.000000e+00         58        441   2.042  ...   \n",
       "3154      19.0  2.220446e-16        260       1899   8.998  ...   \n",
       "3708      44.0  6.000000e+00        288       2070   9.900  ...   \n",
       "1895       2.0  2.220446e-16         54        280   1.640  ...   \n",
       "1894       5.0  1.000000e+00         50        280   1.560  ...   \n",
       "2685       6.0  8.000000e+00         15         69   1.000  ...   \n",
       "\n",
       "      retweets_lag_2  quotes_lag_2  log_likes_lag_1  log_replies_lag_1  \\\n",
       "1972    9.000000e+00  3.000000e+00         2.995732         -36.043653   \n",
       "1783    5.000000e+00  1.000000e+00         5.129899           1.609438   \n",
       "3228    2.800000e+01  7.000000e+00         5.010635         -36.043653   \n",
       "3239    4.200000e+01  5.000000e+00         4.077537         -36.043653   \n",
       "3227    1.600000e+01  2.220446e-16         4.844187           1.386294   \n",
       "3154    2.000000e+01  5.000000e+00         4.406719           0.000000   \n",
       "3708    1.100000e+01  1.000000e+00         4.143135         -36.043653   \n",
       "1895    3.000000e+00  2.000000e+00         3.044522           0.693147   \n",
       "1894    2.220446e-16  2.220446e-16         4.442651         -36.043653   \n",
       "2685    2.000000e+00  2.220446e-16         4.510860         -36.043653   \n",
       "\n",
       "      log_retweets_lag_1  log_quotes_lag_1  log_likes_lag_2  \\\n",
       "1972            1.609438          0.000000         4.043051   \n",
       "1783            3.332205          1.945910         2.995732   \n",
       "3228            3.737670          1.609438         5.129899   \n",
       "3239            2.772589        -36.043653         5.010635   \n",
       "3227            2.995732          1.609438         4.077537   \n",
       "3154            2.397895          0.000000         4.844187   \n",
       "3708            2.944439        -36.043653         4.406719   \n",
       "1895          -36.043653        -36.043653         4.744932   \n",
       "1894            0.693147        -36.043653         3.044522   \n",
       "2685            1.609438          0.000000         4.442651   \n",
       "\n",
       "      log_replies_lag_2  log_retweets_lag_2  log_quotes_lag_2  \n",
       "1972           1.098612            2.197225          1.098612  \n",
       "1783         -36.043653            1.609438          0.000000  \n",
       "3228           1.609438            3.332205          1.945910  \n",
       "3239         -36.043653            3.737670          1.609438  \n",
       "3227         -36.043653            2.772589        -36.043653  \n",
       "3154           1.386294            2.995732          1.609438  \n",
       "3708           0.000000            2.397895          0.000000  \n",
       "1895         -36.043653            1.098612          0.693147  \n",
       "1894           0.693147          -36.043653        -36.043653  \n",
       "2685         -36.043653            0.693147        -36.043653  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
